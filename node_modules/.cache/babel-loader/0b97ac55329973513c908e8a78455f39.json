{"ast":null,"code":"/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n'use strict';\n\nvar PorterStemmer = require('../stemmers/porter_stemmer');\n\nvar events = require('events');\n\nvar parallelTrainer = require('./classifier_train_parallel');\n\nvar Classifier = function Classifier(classifier, stemmer) {\n  this.classifier = classifier;\n  this.docs = [];\n  this.features = {};\n  this.stemmer = stemmer || PorterStemmer;\n  this.lastAdded = 0;\n  this.events = new events.EventEmitter();\n};\n\nfunction addDocument(text, classification) {\n  // Ignore further processing if classification is undefined\n  if (typeof classification === 'undefined') return; // If classification is type of string then make sure it's dosen't have blank space at both end\n\n  if (typeof classification === 'string') {\n    classification = classification.trim();\n  }\n\n  if (typeof text === 'string') {\n    text = this.stemmer.tokenizeAndStem(text, this.keepStops);\n  }\n\n  if (text.length === 0) {\n    // ignore empty documents\n    return;\n  }\n\n  this.docs.push({\n    label: classification,\n    text: text\n  });\n\n  for (var i = 0; i < text.length; i++) {\n    var token = text[i];\n    this.features[token] = (this.features[token] || 0) + 1;\n  }\n}\n\nfunction removeDocument(text, classification) {\n  var docs = this.docs;\n  var doc;\n  var pos;\n\n  if (typeof text === 'string') {\n    text = this.stemmer.tokenizeAndStem(text, this.keepStops);\n  }\n\n  for (var i = 0, ii = docs.length; i < ii; i++) {\n    doc = docs[i];\n\n    if (doc.text.join(' ') === text.join(' ') && doc.label === classification) {\n      pos = i;\n    }\n  } // Remove if there's a match\n\n\n  if (!isNaN(pos)) {\n    this.docs.splice(pos, 1);\n\n    for (var _i = 0, _ii = text.length; _i < _ii; _i++) {\n      delete this.features[text[_i]];\n    }\n  }\n}\n\nfunction textToFeatures(observation) {\n  var features = [];\n\n  if (typeof observation === 'string') {\n    observation = this.stemmer.tokenizeAndStem(observation, this.keepStops);\n  }\n\n  for (var feature in this.features) {\n    if (observation.indexOf(feature) > -1) {\n      features.push(1);\n    } else {\n      features.push(0);\n    }\n  }\n\n  return features;\n}\n\nfunction train() {\n  var totalDocs = this.docs.length;\n\n  for (var i = this.lastAdded; i < totalDocs; i++) {\n    var features = this.textToFeatures(this.docs[i].text);\n    this.classifier.addExample(features, this.docs[i].label);\n    this.events.emit('trainedWithDocument', {\n      index: i,\n      total: totalDocs,\n      doc: this.docs[i]\n    });\n    this.lastAdded++;\n  }\n\n  this.events.emit('doneTraining', true);\n  this.classifier.train();\n}\n\nfunction retrain() {\n  this.classifier = new this.classifier.constructor();\n  this.lastAdded = 0;\n  this.train();\n}\n\nfunction getClassifications(observation) {\n  return this.classifier.getClassifications(this.textToFeatures(observation));\n}\n\nfunction classify(observation) {\n  return this.classifier.classify(this.textToFeatures(observation));\n}\n\nfunction restore(classifier, stemmer) {\n  classifier.stemmer = stemmer || PorterStemmer;\n  classifier.events = new events.EventEmitter();\n  return classifier;\n}\n\nfunction save(filename, callback) {\n  var data = JSON.stringify(this);\n\n  var fs = require('fs');\n\n  var classifier = this;\n  fs.writeFile(filename, data, 'utf8', function (err) {\n    if (callback) {\n      callback(err, err ? null : classifier);\n    }\n  });\n}\n\nfunction load(filename, callback) {\n  var fs = require('fs');\n\n  if (!callback) {\n    return;\n  }\n\n  fs.readFile(filename, 'utf8', function (err, data) {\n    if (err) {\n      callback(err, null);\n    } else {\n      var classifier = JSON.parse(data);\n      callback(err, classifier);\n    }\n  });\n}\n\nfunction setOptions(options) {\n  this.keepStops = !!options.keepStops;\n}\n\nClassifier.prototype.addDocument = addDocument;\nClassifier.prototype.removeDocument = removeDocument;\nClassifier.prototype.train = train;\n\nif (parallelTrainer.Threads) {\n  Classifier.prototype.trainParallel = parallelTrainer.trainParallel;\n  Classifier.prototype.trainParallelBatches = parallelTrainer.trainParallelBatches;\n  Classifier.prototype.retrainParallel = parallelTrainer.retrainParallel;\n}\n\nClassifier.prototype.retrain = retrain;\nClassifier.prototype.classify = classify;\nClassifier.prototype.textToFeatures = textToFeatures;\nClassifier.prototype.save = save;\nClassifier.prototype.getClassifications = getClassifications;\nClassifier.prototype.setOptions = setOptions;\nClassifier.restore = restore;\nClassifier.load = load;\nmodule.exports = Classifier;","map":{"version":3,"sources":["C:/CodingProjects/ABCspelet/node_modules/natural/lib/natural/classifiers/classifier.js"],"names":["PorterStemmer","require","events","parallelTrainer","Classifier","classifier","stemmer","docs","features","lastAdded","EventEmitter","addDocument","text","classification","trim","tokenizeAndStem","keepStops","length","push","label","i","token","removeDocument","doc","pos","ii","join","isNaN","splice","textToFeatures","observation","feature","indexOf","train","totalDocs","addExample","emit","index","total","retrain","constructor","getClassifications","classify","restore","save","filename","callback","data","JSON","stringify","fs","writeFile","err","load","readFile","parse","setOptions","options","prototype","Threads","trainParallel","trainParallelBatches","retrainParallel","module","exports"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA,IAAMA,aAAa,GAAGC,OAAO,CAAC,4BAAD,CAA7B;;AACA,IAAMC,MAAM,GAAGD,OAAO,CAAC,QAAD,CAAtB;;AAEA,IAAME,eAAe,GAAGF,OAAO,CAAC,6BAAD,CAA/B;;AAEA,IAAMG,UAAU,GAAG,SAAbA,UAAa,CAAUC,UAAV,EAAsBC,OAAtB,EAA+B;AAChD,OAAKD,UAAL,GAAkBA,UAAlB;AACA,OAAKE,IAAL,GAAY,EAAZ;AACA,OAAKC,QAAL,GAAgB,EAAhB;AACA,OAAKF,OAAL,GAAeA,OAAO,IAAIN,aAA1B;AACA,OAAKS,SAAL,GAAiB,CAAjB;AACA,OAAKP,MAAL,GAAc,IAAIA,MAAM,CAACQ,YAAX,EAAd;AACD,CAPD;;AASA,SAASC,WAAT,CAAsBC,IAAtB,EAA4BC,cAA5B,EAA4C;AAC1C;AACA,MAAI,OAAOA,cAAP,KAA0B,WAA9B,EAA2C,OAFD,CAI1C;;AACA,MAAI,OAAOA,cAAP,KAA0B,QAA9B,EAAwC;AACtCA,IAAAA,cAAc,GAAGA,cAAc,CAACC,IAAf,EAAjB;AACD;;AAED,MAAI,OAAOF,IAAP,KAAgB,QAApB,EAA8B;AAAEA,IAAAA,IAAI,GAAG,KAAKN,OAAL,CAAaS,eAAb,CAA6BH,IAA7B,EAAmC,KAAKI,SAAxC,CAAP;AAA2D;;AAE3F,MAAIJ,IAAI,CAACK,MAAL,KAAgB,CAApB,EAAuB;AACrB;AACA;AACD;;AAED,OAAKV,IAAL,CAAUW,IAAV,CAAe;AACbC,IAAAA,KAAK,EAAEN,cADM;AAEbD,IAAAA,IAAI,EAAEA;AAFO,GAAf;;AAKA,OAAK,IAAIQ,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGR,IAAI,CAACK,MAAzB,EAAiCG,CAAC,EAAlC,EAAsC;AACpC,QAAMC,KAAK,GAAGT,IAAI,CAACQ,CAAD,CAAlB;AACA,SAAKZ,QAAL,CAAca,KAAd,IAAuB,CAAC,KAAKb,QAAL,CAAca,KAAd,KAAwB,CAAzB,IAA8B,CAArD;AACD;AACF;;AAED,SAASC,cAAT,CAAyBV,IAAzB,EAA+BC,cAA/B,EAA+C;AAC7C,MAAMN,IAAI,GAAG,KAAKA,IAAlB;AACA,MAAIgB,GAAJ;AACA,MAAIC,GAAJ;;AAEA,MAAI,OAAOZ,IAAP,KAAgB,QAApB,EAA8B;AAC5BA,IAAAA,IAAI,GAAG,KAAKN,OAAL,CAAaS,eAAb,CAA6BH,IAA7B,EAAmC,KAAKI,SAAxC,CAAP;AACD;;AAED,OAAK,IAAII,CAAC,GAAG,CAAR,EAAWK,EAAE,GAAGlB,IAAI,CAACU,MAA1B,EAAkCG,CAAC,GAAGK,EAAtC,EAA0CL,CAAC,EAA3C,EAA+C;AAC7CG,IAAAA,GAAG,GAAGhB,IAAI,CAACa,CAAD,CAAV;;AACA,QAAIG,GAAG,CAACX,IAAJ,CAASc,IAAT,CAAc,GAAd,MAAuBd,IAAI,CAACc,IAAL,CAAU,GAAV,CAAvB,IACAH,GAAG,CAACJ,KAAJ,KAAcN,cADlB,EACkC;AAChCW,MAAAA,GAAG,GAAGJ,CAAN;AACD;AACF,GAf4C,CAiB7C;;;AACA,MAAI,CAACO,KAAK,CAACH,GAAD,CAAV,EAAiB;AACf,SAAKjB,IAAL,CAAUqB,MAAV,CAAiBJ,GAAjB,EAAsB,CAAtB;;AAEA,SAAK,IAAIJ,EAAC,GAAG,CAAR,EAAWK,GAAE,GAAGb,IAAI,CAACK,MAA1B,EAAkCG,EAAC,GAAGK,GAAtC,EAA0CL,EAAC,EAA3C,EAA+C;AAC7C,aAAO,KAAKZ,QAAL,CAAcI,IAAI,CAACQ,EAAD,CAAlB,CAAP;AACD;AACF;AACF;;AAED,SAASS,cAAT,CAAyBC,WAAzB,EAAsC;AACpC,MAAMtB,QAAQ,GAAG,EAAjB;;AAEA,MAAI,OAAOsB,WAAP,KAAuB,QAA3B,EAAqC;AAAEA,IAAAA,WAAW,GAAG,KAAKxB,OAAL,CAAaS,eAAb,CAA6Be,WAA7B,EAA0C,KAAKd,SAA/C,CAAd;AAAyE;;AAEhH,OAAK,IAAMe,OAAX,IAAsB,KAAKvB,QAA3B,EAAqC;AACnC,QAAIsB,WAAW,CAACE,OAAZ,CAAoBD,OAApB,IAA+B,CAAC,CAApC,EAAuC;AAAEvB,MAAAA,QAAQ,CAACU,IAAT,CAAc,CAAd;AAAkB,KAA3D,MAAiE;AAAEV,MAAAA,QAAQ,CAACU,IAAT,CAAc,CAAd;AAAkB;AACtF;;AAED,SAAOV,QAAP;AACD;;AAED,SAASyB,KAAT,GAAkB;AAChB,MAAMC,SAAS,GAAG,KAAK3B,IAAL,CAAUU,MAA5B;;AACA,OAAK,IAAIG,CAAC,GAAG,KAAKX,SAAlB,EAA6BW,CAAC,GAAGc,SAAjC,EAA4Cd,CAAC,EAA7C,EAAiD;AAC/C,QAAMZ,QAAQ,GAAG,KAAKqB,cAAL,CAAoB,KAAKtB,IAAL,CAAUa,CAAV,EAAaR,IAAjC,CAAjB;AACA,SAAKP,UAAL,CAAgB8B,UAAhB,CAA2B3B,QAA3B,EAAqC,KAAKD,IAAL,CAAUa,CAAV,EAAaD,KAAlD;AACA,SAAKjB,MAAL,CAAYkC,IAAZ,CAAiB,qBAAjB,EAAwC;AAAEC,MAAAA,KAAK,EAAEjB,CAAT;AAAYkB,MAAAA,KAAK,EAAEJ,SAAnB;AAA8BX,MAAAA,GAAG,EAAE,KAAKhB,IAAL,CAAUa,CAAV;AAAnC,KAAxC;AACA,SAAKX,SAAL;AACD;;AACD,OAAKP,MAAL,CAAYkC,IAAZ,CAAiB,cAAjB,EAAiC,IAAjC;AACA,OAAK/B,UAAL,CAAgB4B,KAAhB;AACD;;AAED,SAASM,OAAT,GAAoB;AAClB,OAAKlC,UAAL,GAAkB,IAAK,KAAKA,UAAL,CAAgBmC,WAArB,EAAlB;AACA,OAAK/B,SAAL,GAAiB,CAAjB;AACA,OAAKwB,KAAL;AACD;;AAED,SAASQ,kBAAT,CAA6BX,WAA7B,EAA0C;AACxC,SAAO,KAAKzB,UAAL,CAAgBoC,kBAAhB,CAAmC,KAAKZ,cAAL,CAAoBC,WAApB,CAAnC,CAAP;AACD;;AAED,SAASY,QAAT,CAAmBZ,WAAnB,EAAgC;AAC9B,SAAO,KAAKzB,UAAL,CAAgBqC,QAAhB,CAAyB,KAAKb,cAAL,CAAoBC,WAApB,CAAzB,CAAP;AACD;;AAED,SAASa,OAAT,CAAkBtC,UAAlB,EAA8BC,OAA9B,EAAuC;AACrCD,EAAAA,UAAU,CAACC,OAAX,GAAqBA,OAAO,IAAIN,aAAhC;AACAK,EAAAA,UAAU,CAACH,MAAX,GAAoB,IAAIA,MAAM,CAACQ,YAAX,EAApB;AACA,SAAOL,UAAP;AACD;;AAED,SAASuC,IAAT,CAAeC,QAAf,EAAyBC,QAAzB,EAAmC;AACjC,MAAMC,IAAI,GAAGC,IAAI,CAACC,SAAL,CAAe,IAAf,CAAb;;AACA,MAAMC,EAAE,GAAGjD,OAAO,CAAC,IAAD,CAAlB;;AACA,MAAMI,UAAU,GAAG,IAAnB;AACA6C,EAAAA,EAAE,CAACC,SAAH,CAAaN,QAAb,EAAuBE,IAAvB,EAA6B,MAA7B,EAAqC,UAAUK,GAAV,EAAe;AAClD,QAAIN,QAAJ,EAAc;AACZA,MAAAA,QAAQ,CAACM,GAAD,EAAMA,GAAG,GAAG,IAAH,GAAU/C,UAAnB,CAAR;AACD;AACF,GAJD;AAKD;;AAED,SAASgD,IAAT,CAAeR,QAAf,EAAyBC,QAAzB,EAAmC;AACjC,MAAMI,EAAE,GAAGjD,OAAO,CAAC,IAAD,CAAlB;;AAEA,MAAI,CAAC6C,QAAL,EAAe;AACb;AACD;;AACDI,EAAAA,EAAE,CAACI,QAAH,CAAYT,QAAZ,EAAsB,MAAtB,EAA8B,UAAUO,GAAV,EAAeL,IAAf,EAAqB;AACjD,QAAIK,GAAJ,EAAS;AACPN,MAAAA,QAAQ,CAACM,GAAD,EAAM,IAAN,CAAR;AACD,KAFD,MAEO;AACL,UAAM/C,UAAU,GAAG2C,IAAI,CAACO,KAAL,CAAWR,IAAX,CAAnB;AACAD,MAAAA,QAAQ,CAACM,GAAD,EAAM/C,UAAN,CAAR;AACD;AACF,GAPD;AAQD;;AAED,SAASmD,UAAT,CAAqBC,OAArB,EAA8B;AAC5B,OAAKzC,SAAL,GAAiB,CAAC,CAAEyC,OAAO,CAACzC,SAA5B;AACD;;AAEDZ,UAAU,CAACsD,SAAX,CAAqB/C,WAArB,GAAmCA,WAAnC;AACAP,UAAU,CAACsD,SAAX,CAAqBpC,cAArB,GAAsCA,cAAtC;AACAlB,UAAU,CAACsD,SAAX,CAAqBzB,KAArB,GAA6BA,KAA7B;;AACA,IAAI9B,eAAe,CAACwD,OAApB,EAA6B;AAC3BvD,EAAAA,UAAU,CAACsD,SAAX,CAAqBE,aAArB,GAAqCzD,eAAe,CAACyD,aAArD;AACAxD,EAAAA,UAAU,CAACsD,SAAX,CAAqBG,oBAArB,GAA4C1D,eAAe,CAAC0D,oBAA5D;AACAzD,EAAAA,UAAU,CAACsD,SAAX,CAAqBI,eAArB,GAAuC3D,eAAe,CAAC2D,eAAvD;AACD;;AACD1D,UAAU,CAACsD,SAAX,CAAqBnB,OAArB,GAA+BA,OAA/B;AACAnC,UAAU,CAACsD,SAAX,CAAqBhB,QAArB,GAAgCA,QAAhC;AACAtC,UAAU,CAACsD,SAAX,CAAqB7B,cAArB,GAAsCA,cAAtC;AACAzB,UAAU,CAACsD,SAAX,CAAqBd,IAArB,GAA4BA,IAA5B;AACAxC,UAAU,CAACsD,SAAX,CAAqBjB,kBAArB,GAA0CA,kBAA1C;AACArC,UAAU,CAACsD,SAAX,CAAqBF,UAArB,GAAkCA,UAAlC;AACApD,UAAU,CAACuC,OAAX,GAAqBA,OAArB;AACAvC,UAAU,CAACiD,IAAX,GAAkBA,IAAlB;AAEAU,MAAM,CAACC,OAAP,GAAiB5D,UAAjB","sourcesContent":["/*\nCopyright (c) 2011, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\n'use strict'\n\nconst PorterStemmer = require('../stemmers/porter_stemmer')\nconst events = require('events')\n\nconst parallelTrainer = require('./classifier_train_parallel')\n\nconst Classifier = function (classifier, stemmer) {\n  this.classifier = classifier\n  this.docs = []\n  this.features = {}\n  this.stemmer = stemmer || PorterStemmer\n  this.lastAdded = 0\n  this.events = new events.EventEmitter()\n}\n\nfunction addDocument (text, classification) {\n  // Ignore further processing if classification is undefined\n  if (typeof classification === 'undefined') return\n\n  // If classification is type of string then make sure it's dosen't have blank space at both end\n  if (typeof classification === 'string') {\n    classification = classification.trim()\n  }\n\n  if (typeof text === 'string') { text = this.stemmer.tokenizeAndStem(text, this.keepStops) }\n\n  if (text.length === 0) {\n    // ignore empty documents\n    return\n  }\n\n  this.docs.push({\n    label: classification,\n    text: text\n  })\n\n  for (let i = 0; i < text.length; i++) {\n    const token = text[i]\n    this.features[token] = (this.features[token] || 0) + 1\n  }\n}\n\nfunction removeDocument (text, classification) {\n  const docs = this.docs\n  let doc\n  let pos\n\n  if (typeof text === 'string') {\n    text = this.stemmer.tokenizeAndStem(text, this.keepStops)\n  }\n\n  for (let i = 0, ii = docs.length; i < ii; i++) {\n    doc = docs[i]\n    if (doc.text.join(' ') === text.join(' ') &&\n        doc.label === classification) {\n      pos = i\n    }\n  }\n\n  // Remove if there's a match\n  if (!isNaN(pos)) {\n    this.docs.splice(pos, 1)\n\n    for (let i = 0, ii = text.length; i < ii; i++) {\n      delete this.features[text[i]]\n    }\n  }\n}\n\nfunction textToFeatures (observation) {\n  const features = []\n\n  if (typeof observation === 'string') { observation = this.stemmer.tokenizeAndStem(observation, this.keepStops) }\n\n  for (const feature in this.features) {\n    if (observation.indexOf(feature) > -1) { features.push(1) } else { features.push(0) }\n  }\n\n  return features\n}\n\nfunction train () {\n  const totalDocs = this.docs.length\n  for (let i = this.lastAdded; i < totalDocs; i++) {\n    const features = this.textToFeatures(this.docs[i].text)\n    this.classifier.addExample(features, this.docs[i].label)\n    this.events.emit('trainedWithDocument', { index: i, total: totalDocs, doc: this.docs[i] })\n    this.lastAdded++\n  }\n  this.events.emit('doneTraining', true)\n  this.classifier.train()\n}\n\nfunction retrain () {\n  this.classifier = new (this.classifier.constructor)()\n  this.lastAdded = 0\n  this.train()\n}\n\nfunction getClassifications (observation) {\n  return this.classifier.getClassifications(this.textToFeatures(observation))\n}\n\nfunction classify (observation) {\n  return this.classifier.classify(this.textToFeatures(observation))\n}\n\nfunction restore (classifier, stemmer) {\n  classifier.stemmer = stemmer || PorterStemmer\n  classifier.events = new events.EventEmitter()\n  return classifier\n}\n\nfunction save (filename, callback) {\n  const data = JSON.stringify(this)\n  const fs = require('fs')\n  const classifier = this\n  fs.writeFile(filename, data, 'utf8', function (err) {\n    if (callback) {\n      callback(err, err ? null : classifier)\n    }\n  })\n}\n\nfunction load (filename, callback) {\n  const fs = require('fs')\n\n  if (!callback) {\n    return\n  }\n  fs.readFile(filename, 'utf8', function (err, data) {\n    if (err) {\n      callback(err, null)\n    } else {\n      const classifier = JSON.parse(data)\n      callback(err, classifier)\n    }\n  })\n}\n\nfunction setOptions (options) {\n  this.keepStops = !!(options.keepStops)\n}\n\nClassifier.prototype.addDocument = addDocument\nClassifier.prototype.removeDocument = removeDocument\nClassifier.prototype.train = train\nif (parallelTrainer.Threads) {\n  Classifier.prototype.trainParallel = parallelTrainer.trainParallel\n  Classifier.prototype.trainParallelBatches = parallelTrainer.trainParallelBatches\n  Classifier.prototype.retrainParallel = parallelTrainer.retrainParallel\n}\nClassifier.prototype.retrain = retrain\nClassifier.prototype.classify = classify\nClassifier.prototype.textToFeatures = textToFeatures\nClassifier.prototype.save = save\nClassifier.prototype.getClassifications = getClassifications\nClassifier.prototype.setOptions = setOptions\nClassifier.restore = restore\nClassifier.load = load\n\nmodule.exports = Classifier\n"]},"metadata":{},"sourceType":"script"}